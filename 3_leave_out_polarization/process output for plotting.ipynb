{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/'\n",
    "TWEET_DIR = '../data/tweets/'\n",
    "NUM_CLUSTERS = 6\n",
    "events = open(DATA_DIR + 'event_names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_filter_method = '_noRT' # make sure to include underscore\n",
    "cluster_method = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_dict = json.load(open(DATA_DIR + \"event_year.json\",\"r\"))\n",
    "polarization_dict = json.load(open(DATA_DIR + \"polarization\"+data_filter_method+\".json\",\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "between_topic_pol = json.load(open(DATA_DIR + \"between_topic_polarization\"+cluster_method+\".json\",\"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting overall polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "y_random = []\n",
    "labels=[]\n",
    "ex = ['fort_lauderdale']  # we exclude Fort Lauderdale because we only have data for the first day after the shooting\n",
    "for e, t in time_dict.items():\n",
    "    if e in ex:\n",
    "        continue\n",
    "    label = e.split('_')\n",
    "    new_label = []\n",
    "    for l in label:\n",
    "        new_label.append(l[0].upper() + l[1:])\n",
    "    new_label = ' '.join(new_label)\n",
    "    \n",
    "    x_val = float(2000+t)\n",
    "    y_val = float(polarization_dict[e][0])\n",
    "    y_random_val = float(float(polarization_dict[e][1]))\n",
    "    x.append(x_val)\n",
    "    y.append(y_val)\n",
    "    y_random.append(y_random_val)\n",
    "    labels.append(new_label)\n",
    "    #labels.append(plt.text(x_val, y_val, new_label, fontsize=8))\n",
    "df = pd.DataFrame.from_dict({'year':np.array(x * 2), 'polarization':np.array(y + y_random), 'label':labels * 2, 'is_actual':['actual value']* len(y) + ['value resulting from random party assignment']* len(y)})\n",
    "df.to_csv(DATA_DIR + \"polarization\"+data_filter_method+\".csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting within vs between topic polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for event in events:\n",
    "    labels = np.load(TWEET_DIR + event + '/' + event + '_cluster_labels_' + str(NUM_CLUSTERS) + cluster_method + '.npy')\n",
    "    topics.extend(list(labels))\n",
    "topics = np.array(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y_between = []\n",
    "y_within = []\n",
    "labels=[]\n",
    "race = []\n",
    "ex = ['fort_lauderdale']\n",
    "for e, t in time_dict.items():\n",
    "    if e in ex:\n",
    "        continue\n",
    "    label = e.split('_')\n",
    "    new_label = []\n",
    "    for l in label:\n",
    "        new_label.append(l[0].upper() + l[1:])\n",
    "    new_label = ' '.join(new_label)\n",
    "    \n",
    "    within_topic_pol = json.load(open(TWEET_DIR +e+\"/\"+e+\"_topic_polarization\"++\".json\",\"r\"))\n",
    "    \n",
    "    # get the topic proportions\n",
    "    data = pd.read_csv('all_events/' + e + '/' + e + '.csv', sep='\\t', lineterminator='\\n',usecols=['remove'])\n",
    "    indices = np.load('all_events/' + e + '/' + e + '_cleaned_indices_partisan.npy')\n",
    "    strict_indices = np.load('all_events/' + e + '/' + e + '_comp_cluster_indices.npy')\n",
    "    strict_labels = np.load('all_events/' + e + '/' + e + '_comp_cluster_labels.npy')\n",
    "    data = data.iloc[indices]\n",
    "    print(len(data))\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data = data.iloc[strict_indices]\n",
    "    data['cluster'] = strict_labels\n",
    "    data = data[~data['remove']]\n",
    "    topics = np.array(data['cluster'])\n",
    "    \n",
    "    \n",
    "    #topics = np.load('all_events/' + e + '/' + e + '_cluster_labels_'+str(num_clusters)+'.npy')\n",
    "    within_topic_pol_val = (np.array([float(within_topic_pol[str(i)][0]) for i in range(num_clusters)]) * np.bincount(topics)).sum() / len(topics)\n",
    "    \n",
    "    x_val = float(2000+t)\n",
    "    y_between_val = float(between_topic_pol[e][0])\n",
    "    y_within_val = within_topic_pol_val\n",
    "    x.append(x_val)\n",
    "    y_between.append(y_between_val)\n",
    "    y_within.append(y_within_val)\n",
    "    labels.append(new_label)\n",
    "    race.append(shooter_race[e])\n",
    "    #labels.append(plt.text(x_val, y_val, new_label, fontsize=8))\n",
    "df = pd.DataFrame.from_dict({'year':np.array(x * 2), 'polarization':np.array(y_between + y_within), 'label':labels * 2, 'kind':['between-topic']* len(y_between) + ['within-topic']* len(y_within), 'race':race * 2})\n",
    "df.to_csv('all_events/strict_topic_polarization_naive_bayes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
